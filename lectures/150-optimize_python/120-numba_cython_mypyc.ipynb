{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ddc58b1-df77-4e30-96dc-ae1997b11166",
   "metadata": {},
   "source": [
    "# Use Numba and cython speed up Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470831e2-c7f4-4430-a2c9-eea1d5ea6994",
   "metadata": {},
   "source": [
    "Numba provides a \"jit\" or a \"just in time\" compiler. Recall that C is a compiled langauge, its source code is optimized and converted to CPU instructions. Python is \"interpreted,\" its code is NOT optimized ahead of time and is interpreted a line at a time. This means that a Python interpreter does not have enough information for optimization.\n",
    "\n",
    "Just in time (JIT) compiler are used in many languages, including Java, C# and even Python is getting a JIT compiler in version 3.13. Numba is also a JIT addon that we can use with any version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c15e85-7709-4951-8565-dd811e3848c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761cd3c2-48ff-45ed-8dec-0eb05a873f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026dc916-2854-4c2c-9c94-190abcc895a5",
   "metadata": {},
   "source": [
    "### An implementation of K-nearest neighbors classifier\n",
    "Code from perplexity.io and Claud.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8287d532-a9ec-4f8e-af61-5470b097a606",
   "metadata": {},
   "source": [
    "#### Python only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067fe62-c190-4770-8f3b-1ac93d51c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(p1, p2):\n",
    "    return math.sqrt(sum((x - y) ** 2 for x, y in zip(p1, p2)))\n",
    "\n",
    "def knn_python(X_train, y_train, X_test, k):\n",
    "    predictions = []\n",
    "    for test_point in X_test:\n",
    "        distances = []\n",
    "        for i, train_point in enumerate(X_train):\n",
    "            dist = euclidean_distance(test_point, train_point)\n",
    "            distances.append((dist, y_train[i]))\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "\n",
    "        nearest_labels = [label for (_, label) in distances[:k]]\n",
    "\n",
    "        # Majority vote, manual count\n",
    "        best_label = None\n",
    "        best_count = 0\n",
    "        for label in set(nearest_labels):\n",
    "            count = nearest_labels.count(label)\n",
    "            if count > best_count:\n",
    "                best_count = count\n",
    "                best_label = label\n",
    "                \n",
    "        predictions.append(best_label)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e6038f-9b05-4814-b450-fac0b4a35607",
   "metadata": {},
   "source": [
    "#### Numpy\n",
    "Numpy could be much faster if it could use specialized functions in its library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a8047-0b43-445e-8096-89b0b5e00691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_numpy(X_train, y_train, X_test, k):\n",
    "    predictions = []\n",
    "    for test_point in X_test:\n",
    "        # Vectorized distance calculation: array subtraction + sum of squares + sqrt\n",
    "        diff = X_train - test_point  # shape (n_train, n_features)\n",
    "        dists = np.sqrt(np.sum(diff ** 2, axis=1))  # shape (n_train,)\n",
    "\n",
    "        # Convert to list of (distance, label) tuples\n",
    "        distances = list(zip(dists.tolist(), y_train.tolist()))\n",
    "\n",
    "        # Sort by distance\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "\n",
    "        nearest_labels = [label for (_, label) in distances[:k]]\n",
    "\n",
    "        # Majority vote, manual count\n",
    "        best_label = None\n",
    "        best_count = 0\n",
    "        for label in set(nearest_labels):\n",
    "            count = nearest_labels.count(label)\n",
    "            if count > best_count:\n",
    "                best_count = count\n",
    "                best_label = label\n",
    "        \n",
    "        predictions.append(best_label)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b88999-a41e-4c3d-bc20-c17060983e56",
   "metadata": {},
   "source": [
    "#### Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c38988-0a91-441e-8be7-d66053c3b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some made up numbers\n",
    "X_train = [[0.93588381, 0.64083873, 0.43191558],\n",
    "           [0.42222037, 0.11649837, 0.06062254],\n",
    "           [0.55167179, 0.92109796, 0.60461583]]\n",
    "y_train = [1, 2, 3]\n",
    "X_test  = [[0.35138874453456725, 0.519960657417942, 0.8637018994564011],\n",
    "             [0.6558387008127351, 0.5067038567727152, 0.17407496226564068],\n",
    "             [0.34327858991593596, 0.6883918432579191, 0.9240662106562946]]\n",
    "\n",
    "X_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train)\n",
    "X_test_np  = np.array(y_train)\n",
    "\n",
    "%timeit knn_python(X_train, y_train, X_test, k=2)\n",
    "%timeit knn_numpy(X_train_np, y_train_np, X_test_np, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b411f-b70b-42a1-8314-69c4996ef539",
   "metadata": {},
   "source": [
    "Shouldn't numpy be MUCH faster than basic Python??\n",
    "\n",
    "#### Scale matters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfaff1-74e9-45c1-a572-fed3cfdf7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "times = []\n",
    "\n",
    "COLUMNS = 3\n",
    "\n",
    "for i in [3, 5, 10, 100, 500, 1_000]:\n",
    "    X_train_np = np.random.rand(i, COLUMNS)\n",
    "    y_train_np = np.random.randint(0, 5, size=i)  # Labels from 0 to 4\n",
    "    X_test_np  = np.random.rand(i, COLUMNS)\n",
    "\n",
    "    X_train = X_train_np.tolist()\n",
    "    y_train = y_train_np.tolist()\n",
    "    X_test  = X_test_np.tolist()\n",
    "\n",
    "    python_time = timeit(lambda: knn_python(X_train, y_train, X_test, k=2), number=10)\n",
    "    numpy_time  = timeit(lambda: knn_numpy(X_train_np, y_train_np, X_test_np, k=2), number=10)\n",
    "\n",
    "    times.append((i, python_time, numpy_time))\n",
    "\n",
    "# Pretty-print\n",
    "df = pd.DataFrame(times, columns=[\"n_samples\", \"python_time\", \"numpy_time\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef4bf6-631e-46b9-a702-8b932fb12ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.line(x='n_samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753cd8b7-4f94-4ac0-9c45-43a0c8f44f76",
   "metadata": {},
   "source": [
    "#### Let's compare numpy with numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d7b8bf-4b70-481a-9097-ae2d59deccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2295eb-683c-4656-b9c7-9b80c67bd5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import numba\n",
    "\n",
    "@numba.njit\n",
    "def euclidean_distance_numba(p1, p2):\n",
    "    total = 0.0\n",
    "    for i in range(len(p1)):\n",
    "        diff = p1[i] - p2[i]\n",
    "        total += diff * diff\n",
    "    return math.sqrt(total)\n",
    "\n",
    "@numba.njit\n",
    "def knn_numba(X_train, y_train, X_test, k):\n",
    "    n_test = X_test.shape[0]\n",
    "    predictions = np.empty(n_test, dtype=y_train.dtype)\n",
    "\n",
    "    for idx in range(n_test):\n",
    "        test_point = X_test[idx]\n",
    "        n_train = X_train.shape[0]\n",
    "\n",
    "        distances = np.empty(n_train)\n",
    "        for i in range(n_train):\n",
    "            distances[i] = euclidean_distance_numba(test_point, X_train[i])\n",
    "\n",
    "        # Simple sort using argsort\n",
    "        sorted_indices = np.argsort(distances)\n",
    "\n",
    "        # Majority vote for top k\n",
    "        label_counts = dict()\n",
    "        for j in range(k):\n",
    "            label = y_train[sorted_indices[j]]\n",
    "            if label in label_counts:\n",
    "                label_counts[label] += 1\n",
    "            else:\n",
    "                label_counts[label] = 1\n",
    "\n",
    "        best_label = -1\n",
    "        best_count = -1\n",
    "        for label, count in label_counts.items():\n",
    "            if count > best_count:\n",
    "                best_label = label\n",
    "                best_count = count\n",
    "\n",
    "        predictions[idx] = best_label\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca02a5c-154a-4d4f-bacd-3e42279e49d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "times = []\n",
    "\n",
    "COLUMNS = 3\n",
    "\n",
    "for i in [3, 5, 10, 100, 500, 1_000]:\n",
    "    X_train_np = np.random.rand(i, COLUMNS)\n",
    "    y_train_np = np.random.randint(0, 5, size=i)  # Labels from 0 to 4\n",
    "    X_test_np  = np.random.rand(i, COLUMNS)\n",
    "\n",
    "    X_train = X_train_np.tolist()\n",
    "    y_train = y_train_np.tolist()\n",
    "    X_test  = X_test_np.tolist()\n",
    "\n",
    "    numba_time  = timeit(lambda: knn_numba(X_train_np, y_train_np, X_test_np, k=2), number=10)\n",
    "\n",
    "    times.append((i, numba_time))\n",
    "\n",
    "# Pretty-print\n",
    "df_numba = pd.DataFrame(times, columns=[\"n_samples\", \"numba_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567aa592-cd30-4d81-9daa-e59185e95380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_numba.numba_time], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa18b8e-463c-4326-8b6a-06da2bf51a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.line(x='n_samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8e0014-7da1-4938-8f38-4aa79af1509b",
   "metadata": {},
   "source": [
    "#### Warning, `numba` can be very finicky\n",
    "\n",
    "For example, numba should not be used with standard Python lists, it works _much_ better with numpy arrays. It does not work with the `yield` keyword. Even if you don't use it explicitely, it is used in some comprehensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94917f57-cb5e-4519-b299-792d06549425",
   "metadata": {},
   "source": [
    "### What if we pre-compile Python, similar to C? `cython` does exactly that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d571a5-9fb7-449a-8740-aa0a0af62787",
   "metadata": {},
   "source": [
    "The scikit-learn library uses cython, as do some other Python libraries in the scipy universe.  cython requires well typed variables via the `cdef` keyword. These types give compilers much more information and helps them optimize code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2c15d2-18eb-4d9b-b030-2a01ebf36d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Cython # make sure it is installed in the correct enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c86ab-fe93-466b-9d57-73da744f3ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c4973d-fb71-4ef6-84fd-16a8b1c619e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from libc.math cimport sqrt\n",
    "\n",
    "ctypedef np.float64_t DTYPE_t\n",
    "ctypedef np.int64_t ITYPE_t\n",
    "\n",
    "def knn_cython(np.ndarray[DTYPE_t, ndim=2] X_train,\n",
    "               np.ndarray[ITYPE_t, ndim=1] y_train,\n",
    "               np.ndarray[DTYPE_t, ndim=2] X_test,\n",
    "               int k):\n",
    "\n",
    "    cdef int n_test = X_test.shape[0]\n",
    "    cdef int n_train = X_train.shape[0]\n",
    "    cdef int n_features = X_train.shape[1]\n",
    "    cdef np.ndarray[ITYPE_t, ndim=1] predictions = np.empty(n_test, dtype=np.int64)\n",
    "\n",
    "    cdef int i, j, idx\n",
    "    cdef double dist\n",
    "    cdef double diff\n",
    "    cdef int best_label\n",
    "    cdef int best_count\n",
    "    cdef int label\n",
    "\n",
    "    cdef np.ndarray[double, ndim=1] distances = np.empty(n_train, dtype=np.float64)\n",
    "    cdef dict label_counts\n",
    "\n",
    "    for idx in range(n_test):\n",
    "        # Compute distances\n",
    "        for i in range(n_train):\n",
    "            dist = 0.0\n",
    "            for j in range(n_features):\n",
    "                diff = X_train[i, j] - X_test[idx, j]\n",
    "                dist += diff * diff\n",
    "            distances[i] = sqrt(dist)\n",
    "\n",
    "        # Sort distances, get sorted indices\n",
    "        sorted_indices = distances.argsort()\n",
    "\n",
    "        # Majority vote\n",
    "        label_counts = {}\n",
    "        best_label = -1\n",
    "        best_count = -1\n",
    "        for i in range(k):\n",
    "            label = y_train[sorted_indices[i]]\n",
    "            if label in label_counts:\n",
    "                label_counts[label] += 1\n",
    "            else:\n",
    "                label_counts[label] = 1\n",
    "\n",
    "            if label_counts[label] > best_count:\n",
    "                best_label = label\n",
    "                best_count = label_counts[label]\n",
    "\n",
    "        predictions[idx] = best_label\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da025b-f8a7-496b-9d9f-e9e8712e18d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "times = []\n",
    "\n",
    "COLUMNS = 3\n",
    "\n",
    "for i in [3, 5, 10, 100, 500, 1_000]:\n",
    "    X_train_np = np.random.rand(i, COLUMNS)\n",
    "    y_train_np = np.random.randint(0, 5, size=i)  # Labels from 0 to 4\n",
    "    X_test_np  = np.random.rand(i, COLUMNS)\n",
    "\n",
    "    X_train = X_train_np.tolist()\n",
    "    y_train = y_train_np.tolist()\n",
    "    X_test  = X_test_np.tolist()\n",
    "\n",
    "    cython_time  = timeit(lambda: knn_cython(X_train_np, y_train_np, X_test_np, k=2), number=10)\n",
    "\n",
    "    times.append((i, cython_time))\n",
    "\n",
    "# Pretty-print\n",
    "df_cython = pd.DataFrame(times, columns=[\"n_samples\", \"cython_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec95e47-b0b9-4418-9298-c038779f2bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_cython.cython_time], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01e7881-f480-4c8d-8f7f-a3e6ae5d270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.line(x='n_samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2793b046-4902-4422-9d03-797b5f3bcd99",
   "metadata": {},
   "source": [
    "### Modern Python already has optional types, what if we use those to help compilers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a52e47-eeff-4e16-9bad-0ecdf846b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install 'mypy[mypyc]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d92b64-f483-4632-9c1d-09c76cecac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mypyc_knn.py\n",
    "import math\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "\n",
    "def euclidean_distance_mypyc(\n",
    "        p1: NDArray[np.float64]\n",
    "        , p2: NDArray[np.float64]) -> float:\n",
    "    return math.sqrt(sum((x - y) ** 2 for x, y in zip(p1, p2)))\n",
    "\n",
    "\n",
    "def knn_python_mypyc(\n",
    "    X_train: NDArray[np.float64],        # shape (n_samples, n_features)\n",
    "    y_train: NDArray[np.int64],          # shape (n_samples,)\n",
    "    X_test: NDArray[np.float64],         # shape (n_test, n_features)\n",
    "    k: int\n",
    ") -> List[int]:                          # returns list of predicted labels (ints)\n",
    "    predictions: List[int] = []\n",
    "    for test_point in X_test:\n",
    "        distances: List[tuple[float, int]] = []\n",
    "        for i, train_point in enumerate(X_train):\n",
    "            dist = euclidean_distance_mypyc(test_point, train_point)\n",
    "            distances.append((dist, int(y_train[i])))  # cast in case numpy type\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "\n",
    "        nearest_labels: List[int] = [label for (_, label) in distances[:k]]\n",
    "\n",
    "        # Majority vote, manual count\n",
    "        best_label: int | None = None\n",
    "        best_count = 0\n",
    "        for label in set(nearest_labels):\n",
    "            count = nearest_labels.count(label)\n",
    "            if count > best_count:\n",
    "                best_count = count\n",
    "                best_label = label\n",
    "\n",
    "        # best_label can’t be None here if k > 0\n",
    "        predictions.append(best_label if best_label is not None else -1)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a722e968-f2d4-4f02-9418-cca69f1e0616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m mypyc mypyc_knn.py\n",
    "\n",
    "# Compile using the mleng environment explicitly (unfortunately)\n",
    "!conda run -n mleng python -m mypyc mypyc_knn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dc1e5d-92b6-49cb-a772-6a3e0e5d011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the src file to force Python to load the .so file\n",
    "!rm mypyc_knn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f09cbb-2ac4-4b00-8008-bfe1fc665d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mypyc_knn\n",
    "print(mypyc_knn.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcefc2c-998e-4932-89d6-b83a5b9dd5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "times = []\n",
    "\n",
    "COLUMNS = 3\n",
    "\n",
    "for i in [3, 5, 10, 100, 500, 1_000]:\n",
    "    X_train_np = np.random.rand(i, COLUMNS)\n",
    "    y_train_np = np.random.randint(0, 5, size=i)  # Labels from 0 to 4\n",
    "    X_test_np  = np.random.rand(i, COLUMNS)\n",
    "\n",
    "    X_train = X_train_np.tolist()\n",
    "    y_train = y_train_np.tolist()\n",
    "    X_test  = X_test_np.tolist()\n",
    "\n",
    "    mypyc_time  = timeit(lambda: mypyc_knn.knn_python_mypyc(X_train_np, y_train_np, X_test_np, k=2), number=10)\n",
    "\n",
    "    times.append((i, mypyc_time))\n",
    "\n",
    "# Pretty-print\n",
    "df_mypyc = pd.DataFrame(times, columns=[\"n_samples\", \"mypyc_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66931d1f-072b-4cbe-9d87-5de430b001cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mypyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f415f-dbae-43ef-89c4-da023b8157ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_mypyc.mypyc_time], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36c04c4-8aaf-48e2-9bd4-9b00af41d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.line(x='n_samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2395ff10-29f1-4913-bcc8-387b282105ba",
   "metadata": {},
   "source": [
    "As you can see, `mypyc` is not able to optimize code as much as `cython`. Data science related code may not be mypyc's best use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacca453-ecd4-4e77-bb5a-b6bb584b04db",
   "metadata": {},
   "source": [
    "### `Mojo` is a new Python derivative, built by a VERY strong tech team\n",
    "We will leave experimenting with it for later time:\n",
    "\n",
    "https://www.modular.com/mojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a41205-1eb6-4d3a-ac6f-6d6023fade86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mleng",
   "language": "python",
   "name": "mleng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
