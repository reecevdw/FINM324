{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5183145d-f67e-4f36-a5b2-b7ab694d70c2",
   "metadata": {},
   "source": [
    "# Understand the limits of memory-only libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d62c94-f7a5-42ba-aba4-0840102a4d57",
   "metadata": {},
   "source": [
    "### Pandas, numpy and Scikit-learn are (mostly) memory-only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b000957-eed8-4ae7-99e6-909fe8564da0",
   "metadata": {},
   "source": [
    "Numpy is designed as a memory only, single-cpu, non-distributed numerics/matrix math library. Scikit-learn and Pandas* are built on top of numpy, hence pay the same trade-off costs as numpy.\n",
    "\n",
    "\n",
    "*(Pandas is moving away from Numpy to include other back-ends, such as Array/Feather formats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15de72c-18de-43c5-a575-aaef06f53cbf",
   "metadata": {},
   "source": [
    "0. Csv vs parquet/feather\n",
    "1. Pandas can't handle files larger than memory\n",
    "    - what if the file is compressed?\n",
    "    - show how much memory on laptop\n",
    "    - generate a file bigger than it with lots of categoires\n",
    "    - try to load the file, but it fails\n",
    "    - load in chunks, but unweildy\n",
    "    - convert categories and load the file just fine\n",
    "3. Try modin/vaex/rapids/etc. and load the file fine, but does it work with sklearn?\n",
    "4. mention distributed frameworks, such as dask/pyspark/koalas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48f8c34-63b3-490b-a4fe-9852c9c4d4e2",
   "metadata": {},
   "source": [
    "### Let's generate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1360f3b0-cfe3-41fe-8761-f583a814dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import urllib.request # to download files\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9df737fa-31f6-4af1-980b-26195c29d88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_gb(df):\n",
    "    memory = df.memory_usage(deep=True).sum() / (1024**3)\n",
    "    return memory.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6ff7a47-1058-4f25-ac01-efd1aac9d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('../../datasets/credit-card-customers/BankChurners.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "feacbf1d-f112-42da-bfe5-cbb8298d37fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004972613416612148"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_gb(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a09e5-afd4-4631-8349-b46f2470cbbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mleng",
   "language": "python",
   "name": "mleng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
